{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4841f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open Downloads/archive, Downloads/archive.zip or Downloads/archive.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to the zip file in your Google Drive\n",
    "zip_file_path = \"Downloads/archive\"\n",
    "# Destination folder to extract the dataset\n",
    "extracted_folder_path = \"Downloads/\"\n",
    "\n",
    "# Extract the zip file\n",
    "!unzip \"$zip_file_path\" -d \"$extracted_folder_path\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06ef5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 16:11:17.435884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_479/3908576244.py:2: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e271a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files train.txt and test.txt generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Function to load images and corresponding labels\n",
    "def load_images_and_labels(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_names = []\n",
    "\n",
    "    # Iterate over folders (labels)\n",
    "    for label_folder in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label_folder)\n",
    "\n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "\n",
    "        # Append label name to the list\n",
    "        label_names.append(label_folder)\n",
    "\n",
    "        # Load images from the label folder\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            # Append image path to the list\n",
    "            images.append(image_path)\n",
    "            # Append label index to the labels list\n",
    "            labels.append(len(label_names) - 1)  # Index of label name\n",
    "\n",
    "    return images, labels, label_names\n",
    "\n",
    "# Load images and labels\n",
    "vggface2_folder = \"Downloads/val\"\n",
    "vggface2_folder1=\"Downloads/test\"\n",
    "images, labels, label_names = load_images_and_labels(vggface2_folder)\n",
    "images1,labels1,label_names1=load_images_and_labels(vggface2_folder1)\n",
    "images=images+images1\n",
    "labels=labels+labels1\n",
    "label_names=label_names1\n",
    "# Split data into train and test sets (adjust the split ratio as needed)\n",
    "split_ratio = 0.8\n",
    "num_images = len(images)\n",
    "num_train = int(num_images * split_ratio)\n",
    "random.seed(42)\n",
    "train_indices = random.sample(range(num_images), num_train)\n",
    "\n",
    "test_indices = list(set(range(num_images)) - set(train_indices))\n",
    "\n",
    "# Write image paths and labels into train.txt and test.txt files\n",
    "def write_to_file(file_path, image_paths, image_labels):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for path, label in zip(image_paths, image_labels):\n",
    "            file.write(f\"{path} {label}\\n\")\n",
    "\n",
    "write_to_file(\"Downloads/train.txt\", [images[i] for i in train_indices], [labels[i] for i in train_indices])\n",
    "write_to_file(\"Downloads/test.txt\", [images[i] for i in test_indices], [labels[i] for i in test_indices])\n",
    "\n",
    "print(\"Files train.txt and test.txt generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1bae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158154\n",
      "1236\n",
      "39539\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weight_decay = 1e-4\n",
    "epoch_num = 15\n",
    "hash_bit = 512\n",
    "num_class = len(set(labels))\n",
    "input_shape = (224, 224, 3)\n",
    "label_smoothing = 0.1\n",
    "\n",
    "# training config\n",
    "batch_size = 128\n",
    "train_num = len(train_indices) #6149\n",
    "print(train_num)\n",
    "iterations_per_epoch = int(train_num / batch_size) + 1\n",
    "warm_iterations = iterations_per_epoch\n",
    "print(iterations_per_epoch)\n",
    "\n",
    "\n",
    "initial_learning_rate = 0.05\n",
    "minimum_learning_rate = 0.0001\n",
    "\n",
    "# test config\n",
    "test_batch_size = 128\n",
    "test_num = len(test_indices)\n",
    "print(test_num)\n",
    "test_iterations = int(test_num / test_batch_size) + 1\n",
    "print(test_iterations)\n",
    "log_file = 'result/vggface2/resnet.txt'\n",
    "\n",
    "# lr\n",
    "learning_rate = [0.1, 0.01, 0.001]\n",
    "boundaries = [80 * iterations_per_epoch, 120 * iterations_per_epoch]\n",
    "\n",
    "\n",
    "# path\n",
    "train_data_path = ''\n",
    "test_data_path = ''\n",
    "imagenet_train_path = 'Downloads/train.txt'\n",
    "imagenet_test_path = 'Downloads/test.txt'\n",
    "\n",
    "\n",
    "short_side_scale = (256, 384)\n",
    "aspect_ratio_scale = (0.8, 1.25)\n",
    "hue_delta = (-36, 36)\n",
    "saturation_scale = (0.6, 1.4)\n",
    "brightness_scale = (0.6, 1.4)\n",
    "pca_std = 0.1\n",
    "\n",
    "mean = [103.939, 116.779, 123.68]\n",
    "std = [58.393, 57.12, 57.375]\n",
    "eigval = [55.46, 4.794, 1.148]\n",
    "eigvec = [[-0.5836, -0.6948, 0.4203],\n",
    "          [-0.5808, -0.0045, -0.8140],\n",
    "          [-0.5675, 0.7192, 0.4009]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c46534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.0'),)\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python\n",
    "!pip install opencv-python\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "|------|\n",
    "|      | height, y\n",
    "|      |\n",
    "|------|\n",
    " width, x\n",
    "\"\"\"\n",
    "\n",
    "def random_size(image, target_size=None):\n",
    "    height, width, _ = np.shape(image)\n",
    "    if target_size is None:\n",
    "        # for test\n",
    "        # target size is fixed\n",
    "        target_size = np.random.randint(*short_side_scale)\n",
    "    if height < width:\n",
    "        size_ratio = target_size / height\n",
    "    else:\n",
    "        size_ratio = target_size / width\n",
    "    resize_shape = (int(width * size_ratio), int(height * size_ratio))  # width and height in cv2 are opposite to np.shape()\n",
    "    return cv2.resize(image, resize_shape)\n",
    "\n",
    "def random_aspect(image):\n",
    "    height, width, _ = np.shape(image)\n",
    "    aspect_ratio = np.random.uniform(*aspect_ratio_scale)\n",
    "    if height < width:\n",
    "        resize_shape = (int(width * aspect_ratio), height)\n",
    "    else:\n",
    "        resize_shape = (width, int(height * aspect_ratio))\n",
    "    return cv2.resize(image, resize_shape)\n",
    "\n",
    "def random_crop(image):\n",
    "    height, width, _ = np.shape(image)\n",
    "    input_height, input_width, _ = input_shape\n",
    "    crop_x = np.random.randint(0, width - input_width)\n",
    "    crop_y = np.random.randint(0, height - input_height)\n",
    "    return image[crop_y: crop_y + input_height, crop_x: crop_x + input_width, :]\n",
    "\n",
    "def random_flip(image):\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    return image\n",
    "\n",
    "def random_hsv(image):\n",
    "    random_h = np.random.uniform(*hue_delta)\n",
    "    random_s = np.random.uniform(*saturation_scale)\n",
    "    random_v = np.random.uniform(*brightness_scale)\n",
    "\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    image_hsv[:, :, 0] = image_hsv[:, :, 0] + random_h % 360.0  # hue\n",
    "    image_hsv[:, :, 1] = np.minimum(image_hsv[:, :, 1] * random_s, 1.0)  # saturation\n",
    "    image_hsv[:, :, 2] = np.minimum(image_hsv[:, :, 2] * random_v, 255.0)  # brightness\n",
    "\n",
    "    return cv2.cvtColor(image_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def random_pca(image):\n",
    "    alpha = np.random.normal(0, pca_std, size=(3,))\n",
    "    offset = np.dot(eigvec * alpha, eigval)\n",
    "    image = image + offset\n",
    "    return np.maximum(np.minimum(image, 255.0), 0.0)\n",
    "\n",
    "def normalize(image):\n",
    "    for i in range(3):\n",
    "        image[..., i] = (image[..., i] - mean[i]) / std[i]\n",
    "    return image\n",
    "\n",
    "def center_crop(image):\n",
    "    height, width, _ = np.shape(image)\n",
    "    input_height, input_width, _ = input_shape\n",
    "    crop_x = (width - input_width) // 2\n",
    "    crop_y = (height - input_height) // 2\n",
    "    return image[crop_y: crop_y + input_height, crop_x: crop_x + input_width, :]\n",
    "\n",
    "def test_10_crop(image):\n",
    "    \"\"\"\n",
    "    Standard 10 crop for test.\n",
    "    Crop 4 corner and 1 center.\n",
    "    Then flip it.\n",
    "    \"\"\"\n",
    "    height, width, _ = np.shape(image)\n",
    "    input_height, input_width, _ = input_shape\n",
    "    center_crop_x = (width - input_width) // 2\n",
    "    center_crop_y = (height - input_height) // 2\n",
    "\n",
    "    images = []\n",
    "    images.append(image[:input_height, :input_width, :])  # left top\n",
    "    images.append(image[:input_height, -input_width:, :])  # right top\n",
    "    images.append(image[-input_height:, :input_width, :])  # left bottom\n",
    "    images.append(image[-input_height:, -input_width:, :])  # right bottom\n",
    "    images.append(image[center_crop_y: center_crop_y + input_height, center_crop_x: center_crop_x + input_width, :])\n",
    "\n",
    "    image = cv2.flip(image, 1)\n",
    "    images.append(image[:input_height, :input_width, :])  # left top\n",
    "    images.append(image[:input_height, -input_width:, :])  # right top\n",
    "    images.append(image[-input_height:, :input_width, :])  # left bottom\n",
    "    images.append(image[-input_height:, -input_width:, :])  # right bottom\n",
    "    images.append(image[center_crop_y: center_crop_y + input_height, center_crop_x: center_crop_x + input_width, :])\n",
    "\n",
    "    return np.array(images, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01429d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import Model, models, Input, regularizers\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, InceptionV3, DenseNet121, VGG16\n",
    "\n",
    "\n",
    "\n",
    "class VGG16Net(Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Net, self).__init__()\n",
    "        self.base_model = VGG16(weights='imagenet', include_top=False, pooling='max')\n",
    "        # self.base_model.trainable = False\n",
    "        for i in range(len(self.base_model.layers) - 2):  # print(len(model.layers))=23\n",
    "            self.base_model.layers[i].trainable = False\n",
    "        self.d1 = Dense(units=hash_bit, activation=tf.nn.sigmoid)\n",
    "        self.d2 = Dense(units=num_class, activation=tf.nn.softmax)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        hash_code = self.d1(x)\n",
    "        prediction = self.d2(hash_code)\n",
    "        return prediction, hash_code\n",
    "\n",
    "\n",
    "def Resnet_Model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, layers=tf.keras.layers, input_shape=(224, 224, 3))\n",
    "    print(len(base_model.layers))  # 175\n",
    "    #for layer in base_model.layers[:170]:\n",
    "    #    layer.trainable = False\n",
    "    #for layer in base_model.layers[170:]:\n",
    "    #    layer.trainable = True\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name='average_pool')(x)\n",
    "    x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "    hash_value = tf.keras.layers.Dense(units=hash_bit, activation=None, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    # hash_value = tf.keras.layers.Dense(units=hash_bit, activation=None)(x)\n",
    "    hash_value = tf.keras.layers.BatchNormalization()(hash_value)\n",
    "    hash_value = tf.keras.layers.Activation(\"sigmoid\")(hash_value)\n",
    "    prediction = tf.keras.layers.Dense(units=num_class, activation=\"softmax\",\n",
    "                                       kernel_regularizer=regularizers.l2(0.001))(hash_value)\n",
    "    # prediction = tf.keras.layers.Dense(units=num_class, activation=\"softmax\")(hash_value)\n",
    "    model = models.Model(inputs=base_model.input, outputs=[prediction, hash_value])\n",
    "    return model\n",
    "\n",
    "\n",
    "def DenseNet_Model():\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    print(len(base_model.layers))  # 427\n",
    "    for layer in base_model.layers[:415]:\n",
    "       layer.trainable = False\n",
    "    for layer in base_model.layers[415:]:\n",
    "       layer.trainable = True\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name='average_pool')(x)\n",
    "    x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "    #x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    hash_value = tf.keras.layers.Dense(units=hash_bit, activation=None)(x)\n",
    "    hash_value = tf.keras.layers.BatchNormalization()(hash_value)\n",
    "    hash_value = tf.keras.layers.Activation(\"sigmoid\")(hash_value)\n",
    "    prediction = tf.keras.layers.Dense(units=num_class, activation=\"softmax\")(hash_value)\n",
    "    model = models.Model(inputs=base_model.input, outputs=[prediction, hash_value])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b57e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_list(list_path, image_root_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open(list_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines = line.replace('\\n', '').split('\\t')\n",
    "            if len(lines) == 1:\n",
    "                lines = line.replace('\\n', '').split()\n",
    "            #print(lines)\n",
    "            # images.append(os.path.join(image_root_path, line[0]))\n",
    "            images.append(image_root_path + lines[0])\n",
    "            labels.append(int(lines[1]))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_image(image_path, label, augment=False, crop_10=False):\n",
    "    \"\"\"\n",
    "    In training, it is highly recommended to set the augment to true.\n",
    "    In test, the standard 10-crop test [1] is provided for fair comparison.\n",
    "    [1] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path.numpy().decode()).astype(np.float32)\n",
    "\n",
    "    if augment:\n",
    "        image = random_aspect(image)\n",
    "        image = random_size(image)\n",
    "        image = random_crop(image)\n",
    "        image = random_flip(image)\n",
    "        image = random_hsv(image)\n",
    "        image = random_pca(image)\n",
    "    else:\n",
    "        image = random_size(image, target_size=256)\n",
    "        if crop_10:\n",
    "            image = test_10_crop(image)\n",
    "        else:\n",
    "            image = center_crop(image)\n",
    "\n",
    "    image = normalize(image)\n",
    "\n",
    "    label_one_hot = np.zeros(num_class)\n",
    "    label_one_hot[label] = 1.0\n",
    "\n",
    "    return image, label_one_hot\n",
    "\n",
    "\n",
    "def train_iterator(list_path=imagenet_train_path):\n",
    "    # list_path图片名称，train_data_path图片前缀地址\n",
    "    \n",
    "\n",
    "    images, labels = load_list(list_path, train_data_path)\n",
    "    #print(images, labels)\n",
    "    #with open(\"image-labels.txt\", 'w') as f:\n",
    "    #        f.write(\"images\"+str(images))\n",
    "    #        f.write(\"\\n\")\n",
    "    #        f.write(\"labels\"+str(labels))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    dataset = dataset.shuffle(len(images))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: tf.py_function(load_image, inp=[x, y, True, False], Tout=[tf.float32, tf.float32]),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    it = dataset.__iter__()\n",
    "    return it\n",
    "\n",
    "\n",
    "def test_iterator(list_path=imagenet_test_path):\n",
    "    images, labels = load_list(list_path, test_data_path)\n",
    "    \n",
    "    print(\"images:\",len(images),\"labels:\",len(labels))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: tf.py_function(load_image, inp=[x, y, False, False], Tout=[tf.float32, tf.float32]),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    it = dataset.__iter__()\n",
    "    return it\n",
    "\n",
    "\n",
    "def test_10_crop_iterator(list_path=imagenet_test_path):\n",
    "    images, labels = load_list(list_path, test_data_path)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: tf.py_function(load_image, inp=[x, y, False, True], Tout=[tf.float32, tf.float32]),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    it = dataset.__iter__()\n",
    "    return it\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Annotate the 'normalize' function for visualization\n",
    "#     # it = train_iterator()\n",
    "#     it = test_iterator('/content/test.txt')\n",
    "#     images, labels = it.next()\n",
    "#     # print(np.shape(images), np.shape(labels))\n",
    "#     for i in range(10):\n",
    "#         print(np.where(labels[i].numpy() != 0))\n",
    "#         cv2_imshow( images[i].numpy().astype(np.uint8))\n",
    "#         cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde3afa6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 16:13:05.473356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-05-02 16:13:05.635861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA A100 80GB PCIe major: 8 minor: 0 memoryClockRate(GHz): 1.41\n",
      "pciBusID: 0000:4b:00.0\n",
      "2024-05-02 16:13:05.635907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-05-02 16:13:05.643114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-05-02 16:13:05.690930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-05-02 16:13:05.691410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-05-02 16:13:05.692157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-05-02 16:13:05.693212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-05-02 16:13:05.693395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-05-02 16:13:05.697048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2024-05-02 16:13:05.735264: I tensorflow/core/platform/profile_utils/cpu_utils.cc:109] CPU Frequency: 2100000000 Hz\n",
      "2024-05-02 16:13:05.742016: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x51ff190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-02 16:13:05.742109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-05-02 16:13:05.929274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2856590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-02 16:13:05.929321: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2024-05-02 16:13:05.930721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA A100 80GB PCIe major: 8 minor: 0 memoryClockRate(GHz): 1.41\n",
      "pciBusID: 0000:4b:00.0\n",
      "2024-05-02 16:13:05.930755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-05-02 16:13:05.930779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-05-02 16:13:05.930787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-05-02 16:13:05.930795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-05-02 16:13:05.930802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-05-02 16:13:05.930810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-05-02 16:13:05.930817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-05-02 16:13:05.933069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2024-05-02 16:13:05.933101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-05-02 16:13:06.178932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-05-02 16:13:06.178983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n",
      "2024-05-02 16:13:06.178989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n",
      "2024-05-02 16:13:06.181522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 78807 MB memory) -> physical GPU (device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:4b:00.0, compute capability: 8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 9s 0us/step\n",
      "175\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pool (GlobalAveragePool (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pool[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 480)          246240      activation[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,885,088\n",
      "Trainable params: 24,830,944\n",
      "Non-trainable params: 54,144\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow will not use sklearn by default. This improves performance in some cases. To enable sklearn export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "WARNING:tensorflow:TensorFlow will not use Dask by default. This improves performance in some cases. To enable Dask export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "WARNING:tensorflow:TensorFlow will not use Pandas by default. This improves performance in some cases. To enable Pandas export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                | 0/1236 [00:00<?, ?it/s]2024-05-02 16:13:32.832379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-05-02 16:13:33.814219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [10:18<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:3.645759, l2_loss:0.465334,hash_loss:0.186799 ,accuracy:0.273229\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:31<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:2.571139, accuracy:0.425387\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:47<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:1.601034, l2_loss:0.575956,hash_loss:0.159137 ,accuracy:0.635107\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:22<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:1.390144, accuracy:0.667199\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:24<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:1.013003, l2_loss:0.635287,hash_loss:0.147398 ,accuracy:0.762427\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:30<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.922199, accuracy:0.781412\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:49<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.744212, l2_loss:0.662219,hash_loss:0.140478 ,accuracy:0.824680\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:36<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.706540, accuracy:0.830644\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:58<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.578722, l2_loss:0.670191,hash_loss:0.135700 ,accuracy:0.862238\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:42<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.538038, accuracy:0.870176\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.463008, l2_loss:0.666240,hash_loss:0.132127 ,accuracy:0.889987\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:54<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.483723, accuracy:0.881315\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:21<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.367985, l2_loss:0.655063,hash_loss:0.129417 ,accuracy:0.913342\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:02<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.375473, accuracy:0.910587\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:19<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.296764, l2_loss:0.640993,hash_loss:0.127321 ,accuracy:0.930737\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:14<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.327077, accuracy:0.920922\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:38<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.240788, l2_loss:0.627137,hash_loss:0.125675 ,accuracy:0.944421\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:07<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.283344, accuracy:0.931213\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:18<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.195033, l2_loss:0.615505,hash_loss:0.124457 ,accuracy:0.955577\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:10<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.224502, accuracy:0.945427\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:05<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.158140, l2_loss:0.607218,hash_loss:0.123512 ,accuracy:0.964976\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:08<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.188722, accuracy:0.954535\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:24<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.134698, l2_loss:0.602492,hash_loss:0.122868 ,accuracy:0.970811\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:11<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.179514, accuracy:0.956280\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:10<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.124380, l2_loss:0.600630,hash_loss:0.122528 ,accuracy:0.973832\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:06<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.171788, accuracy:0.957746\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [08:57<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.118400, l2_loss:0.600348,hash_loss:0.122457 ,accuracy:0.974951\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:02<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.170903, accuracy:0.958176\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:05<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:0.117739, l2_loss:0.600342,hash_loss:0.122424 ,accuracy:0.975134\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:59<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:0.170801, accuracy:0.958227\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python?\n",
    "# -*- coding: utf-8 -*-import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "#import cv2\n",
    "from tensorflow.keras import models, optimizers, Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# from load_data import train_iterator, test_iterator\n",
    "import tensorflow as tf\n",
    "plot_train_loss=[]\n",
    "plot_test_loss=[]\n",
    "plot_train_acc=[]\n",
    "plot_test_acc=[]\n",
    "\n",
    "#import datetime\n",
    "#current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# log_dir = 'logs/Resnet/' + \"cos\"\n",
    "# summary_writer = tf.summary.create_file_writer(log_dir) \n",
    "\n",
    "class CosineDecayWithWarmUP(tf.keras.experimental.CosineDecay):\n",
    "    def __init__(self, initial_learning_rate, decay_steps, alpha=0.0, warm_up_step=0, name=None):\n",
    "        self.warm_up_step = warm_up_step\n",
    "        super(CosineDecayWithWarmUP, self).__init__(initial_learning_rate=initial_learning_rate,\n",
    "                                                    decay_steps=decay_steps,\n",
    "                                                    alpha=alpha,\n",
    "                                                    name=name)\n",
    "\n",
    "def hash_loss_fn(hash_input):\n",
    "    loss1 = -1 * tf.reduce_mean(tf.square(hash_input - 0.5)) + 0.25  # 最大值为0.25\n",
    "    loss2 = tf.reduce_mean(tf.square(tf.reduce_mean(hash_input, axis=1) - 0.5))\n",
    "    return loss1 + loss2\n",
    "\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    cross_entropy = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return tf.reduce_mean(cross_entropy)\n",
    "\n",
    "\n",
    "def l2_loss(model, weights=weight_decay):\n",
    "    variable_list = []\n",
    "    for v in model.trainable_variables:\n",
    "        if 'kernel' in v.name:\n",
    "            variable_list.append(tf.nn.l2_loss(v))\n",
    "    return tf.add_n(variable_list) * weights\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_num = tf.equal(tf.argmax(y_true, -1), tf.argmax(y_pred, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_num, dtype=tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction, hash_value = model(x, training=True)  # 修改\n",
    "        hash_loss = hash_loss_fn(hash_value)  # 修改\n",
    "        ce = cross_entropy(y, prediction)\n",
    "        l2 = l2_loss(model)\n",
    "        loss = ce + l2 + hash_loss  # 修改\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return ce, hash_loss, prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, x, y):\n",
    "    prediction, _ = model(x, training=False)  # 修改\n",
    "    ce = cross_entropy(y, prediction)\n",
    "    return ce, prediction\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_iterator, log_file):\n",
    "    sum_loss = 0\n",
    "    sum_hash_loss = 0\n",
    "    sum_accuracy = 0\n",
    "\n",
    "    for i in tqdm(range(iterations_per_epoch)):\n",
    "        x, y = train_iterator.next()\n",
    "        loss, hash_loss, prediction = train_step(model, optimizer, x, y)\n",
    "        sum_hash_loss += hash_loss\n",
    "        sum_loss += loss\n",
    "        sum_accuracy += accuracy(y, prediction)\n",
    "\n",
    "    print('ce_loss:%f, l2_loss:%f,hash_loss:%f ,accuracy:%f' %\n",
    "          (sum_loss / iterations_per_epoch, l2_loss(model), sum_hash_loss / iterations_per_epoch,\n",
    "           sum_accuracy / iterations_per_epoch))\n",
    "    log_file.write('train: ce loss: {:.4f}, l2 loss: {:.4f}, hash_loss: {:.4f}, accuracy: {:.4f}\\n'.format(sum_loss / iterations_per_epoch, l2_loss(model), \n",
    "    sum_hash_loss / iterations_per_epoch, sum_accuracy / iterations_per_epoch ))\n",
    "    plot_train_loss.append(sum_loss/iterations_per_epoch)\n",
    "    plot_train_loss.append(sum_accuracy/iterations_per_epoch)\n",
    "\n",
    "def test(model, test_iter, log_file):\n",
    "    sum_loss = 0\n",
    "    sum_accuracy = 0\n",
    "    test_data_iterator = test_iterator()\n",
    "\n",
    "    for i in tqdm(range(test_iter)):\n",
    "        x, y = test_data_iterator.next()\n",
    "        x = tf.cast(x, tf.float32)  # 将测试集中的图像编码成float32\n",
    "        loss, prediction = test_step(model, x, y)\n",
    "        sum_loss += loss\n",
    "        sum_accuracy += accuracy(y, prediction)\n",
    "    print('test, loss:%f, accuracy:%f' %\n",
    "          (sum_loss / test_iterations, sum_accuracy / test_iterations))\n",
    "    log_file.write('test: loss: {:.4f}, accuracy: {:.4f}\\n'.format(sum_loss / test_iterations, sum_accuracy / test_iterations))\n",
    "    plot_test_loss.append(sum_loss/test_iterations)\n",
    "    plot_test_loss.append(sum_accuracy/test_iterations)\n",
    "    return sum_accuracy / test_iterations\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # gpu config\n",
    "    #gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "    #for gpu in gpus:\n",
    "    #    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    import os\n",
    "\n",
    "    #os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "    #physical_devices = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "    #print(physical_devices)\n",
    "\n",
    "    #tf.config.experimental.set_memory_growth(device=physical_devices[0], enable=True)\n",
    "\n",
    "    # show\n",
    "    model = Resnet_Model()\n",
    "    model.build((None,224,224,3))\n",
    "    model.summary()\n",
    "\n",
    "    # train-cos\n",
    "    learning_rate_schedules = CosineDecayWithWarmUP(initial_learning_rate=initial_learning_rate,\n",
    "                                                decay_steps=epoch_num * iterations_per_epoch - warm_iterations,\n",
    "                                                alpha=minimum_learning_rate,\n",
    "                                                warm_up_step=warm_iterations)\n",
    "    optimizer = optimizers.SGD(learning_rate=learning_rate_schedules, momentum=0.9)\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model)\n",
    "    \n",
    "    # train\n",
    "    #learning_rate_schedules = optimizers.schedules.PiecewiseConstantDecay(c.boundaries, c.learning_rate)\n",
    "    #optimizer = optimizers.SGD(learning_rate=learning_rate_schedules, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    # optimizer = optimizers.Adam(learning_rate=learning_rate_schedules)\n",
    "    # optimizer = optimizers.Adam()\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model)\n",
    "\n",
    "    train_data_iterator = train_iterator()\n",
    "    for epoch in range(epoch_num):\n",
    "        print(epoch)\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write('epoch:{}\\n'.format(epoch))\n",
    "            train(model, optimizer, train_data_iterator, f)\n",
    "            test_acc = test(model, test_iterations, f)\n",
    "        if test_acc > 0:\n",
    "            name = \"./checkpoint/Resnet/\" + str(np.round(test_acc.numpy(), 3)) + '/model.ckpt'\n",
    "            if not os.path.exists(\"./checkpoint/Resnet/\" + str(np.round(test_acc.numpy(), 3))):\n",
    "                os.makedirs(\"./checkpoint/Resnet/\" + str(np.round(test_acc.numpy(), 3)))\n",
    "            checkpoint.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b619d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[43mepoch_num\u001b[49m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(pochs, plot_train_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(pochs, plot_test_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch_num' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pochs = range(epoch_num)\n",
    "plt.plot(pochs, plot_train_loss, label='Train Loss')\n",
    "plt.plot(pochs, plot_test_loss, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pochs = range(epoch_num)\n",
    "plt.plot(pochs, plot_train_acc, label='Train Accuracy')\n",
    "plt.plot(pochs, plot_test_acc, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Accuracy')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
