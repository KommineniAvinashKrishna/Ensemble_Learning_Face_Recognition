{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd668d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 16:12:05.287597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_479/3908576244.py:2: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d4701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files train.txt and test.txt generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Function to load images and corresponding labels\n",
    "def load_images_and_labels(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_names = []\n",
    "\n",
    "    # Iterate over folders (labels)\n",
    "    for label_folder in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label_folder)\n",
    "\n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "\n",
    "        # Append label name to the list\n",
    "        label_names.append(label_folder)\n",
    "\n",
    "        # Load images from the label folder\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            # Append image path to the list\n",
    "            images.append(image_path)\n",
    "            # Append label index to the labels list\n",
    "            labels.append(len(label_names) - 1)  # Index of label name\n",
    "\n",
    "    return images, labels, label_names\n",
    "\n",
    "# Load images and labels\n",
    "vggface2_folder = \"Downloads/val\"\n",
    "vggface2_folder1=\"Downloads/test\"\n",
    "images, labels, label_names = load_images_and_labels(vggface2_folder)\n",
    "images1,labels1,label_names1=load_images_and_labels(vggface2_folder1)\n",
    "images=images+images1\n",
    "labels=labels+labels1\n",
    "label_names=label_names1\n",
    "# Split data into train and test sets (adjust the split ratio as needed)\n",
    "split_ratio = 0.8\n",
    "num_images = len(images)\n",
    "num_train = int(num_images * split_ratio)\n",
    "random.seed(42)\n",
    "train_indices = random.sample(range(num_images), num_train)\n",
    "random.seed(42)\n",
    "test_indices = list(set(range(num_images)) - set(train_indices))\n",
    "\n",
    "# Write image paths and labels into train.txt and test.txt files\n",
    "def write_to_file(file_path, image_paths, image_labels):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for path, label in zip(image_paths, image_labels):\n",
    "            file.write(f\"{path} {label}\\n\")\n",
    "\n",
    "write_to_file(\"Downloads/den_train.txt\", [images[i] for i in train_indices], [labels[i] for i in train_indices])\n",
    "write_to_file(\"Downloads/den_test.txt\", [images[i] for i in test_indices], [labels[i] for i in test_indices])\n",
    "\n",
    "print(\"Files train.txt and test.txt generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "941f12c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158154\n",
      "1236\n",
      "39539\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weight_decay = 1e-4\n",
    "epoch_num = 15\n",
    "hash_bit = 512\n",
    "num_class = len(set(labels))\n",
    "input_shape = (224, 224, 3)\n",
    "label_smoothing = 0.1\n",
    "\n",
    "# training config\n",
    "batch_size = 128\n",
    "train_num = len(train_indices) #6149\n",
    "print(train_num)\n",
    "iterations_per_epoch = int(train_num / batch_size) + 1\n",
    "warm_iterations = iterations_per_epoch\n",
    "print(iterations_per_epoch)\n",
    "\n",
    "\n",
    "initial_learning_rate = 0.05\n",
    "minimum_learning_rate = 0.0001\n",
    "\n",
    "# test config\n",
    "test_batch_size = 128\n",
    "test_num = len(test_indices)\n",
    "print(test_num)\n",
    "test_iterations = int(test_num / test_batch_size) + 1\n",
    "\n",
    "log_file = 'result/vggface2/densene.txt'\n",
    "\n",
    "# lr\n",
    "learning_rate = [0.1, 0.01, 0.001]\n",
    "boundaries = [80 * iterations_per_epoch, 120 * iterations_per_epoch]\n",
    "\n",
    "\n",
    "# path\n",
    "train_data_path = ''\n",
    "test_data_path = ''\n",
    "imagenet_train_path = 'Downloads/den_train.txt'\n",
    "imagenet_test_path = 'Downloads/den_test.txt'\n",
    "\n",
    "\n",
    "short_side_scale = (256, 384)\n",
    "aspect_ratio_scale = (0.8, 1.25)\n",
    "hue_delta = (-36, 36)\n",
    "saturation_scale = (0.6, 1.4)\n",
    "brightness_scale = (0.6, 1.4)\n",
    "pca_std = 0.1\n",
    "\n",
    "mean = [103.939, 116.779, 123.68]\n",
    "std = [58.393, 57.12, 57.375]\n",
    "eigval = [55.46, 4.794, 1.148]\n",
    "eigvec = [[-0.5836, -0.6948, 0.4203],\n",
    "          [-0.5808, -0.0045, -0.8140],\n",
    "          [-0.5675, 0.7192, 0.4009]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd69acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae93cc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.0'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "|------|\n",
    "|      | height, y\n",
    "|      |\n",
    "|------|\n",
    " width, x\n",
    "\"\"\"\n",
    "\n",
    "def random_size(image, target_size=None):\n",
    "    height, width, _ = np.shape(image)\n",
    "    if target_size is None:\n",
    "        # for test\n",
    "        # target size is fixed\n",
    "        target_size = np.random.randint(*short_side_scale)\n",
    "    if height < width:\n",
    "        size_ratio = target_size / height\n",
    "    else:\n",
    "        size_ratio = target_size / width\n",
    "    resize_shape = (int(width * size_ratio), int(height * size_ratio))  # width and height in cv2 are opposite to np.shape()\n",
    "    return cv2.resize(image, resize_shape)\n",
    "\n",
    "def random_aspect(image):\n",
    "    height, width, _ = np.shape(image)\n",
    "    aspect_ratio = np.random.uniform(*aspect_ratio_scale)\n",
    "    if height < width:\n",
    "        resize_shape = (int(width * aspect_ratio), height)\n",
    "    else:\n",
    "        resize_shape = (width, int(height * aspect_ratio))\n",
    "    return cv2.resize(image, resize_shape)\n",
    "\n",
    "def random_crop(image):\n",
    "    height, width, _ = np.shape(image)\n",
    "    input_height, input_width, _ = input_shape\n",
    "    crop_x = np.random.randint(0, width - input_width)\n",
    "    crop_y = np.random.randint(0, height - input_height)\n",
    "    return image[crop_y: crop_y + input_height, crop_x: crop_x + input_width, :]\n",
    "\n",
    "def random_flip(image):\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    return image\n",
    "\n",
    "def random_hsv(image):\n",
    "    random_h = np.random.uniform(*hue_delta)\n",
    "    random_s = np.random.uniform(*saturation_scale)\n",
    "    random_v = np.random.uniform(*brightness_scale)\n",
    "\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    image_hsv[:, :, 0] = image_hsv[:, :, 0] + random_h % 360.0  # hue\n",
    "    image_hsv[:, :, 1] = np.minimum(image_hsv[:, :, 1] * random_s, 1.0)  # saturation\n",
    "    image_hsv[:, :, 2] = np.minimum(image_hsv[:, :, 2] * random_v, 255.0)  # brightness\n",
    "\n",
    "    return cv2.cvtColor(image_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def random_pca(image):\n",
    "    alpha = np.random.normal(0, pca_std, size=(3,))\n",
    "    offset = np.dot(eigvec * alpha, eigval)\n",
    "    image = image + offset\n",
    "    return np.maximum(np.minimum(image, 255.0), 0.0)\n",
    "\n",
    "def normalize(image):\n",
    "    for i in range(3):\n",
    "        image[..., i] = (image[..., i] - mean[i]) / std[i]\n",
    "    return image\n",
    "\n",
    "def center_crop(image):\n",
    "    height, width, _ = np.shape(image)\n",
    "    input_height, input_width, _ = input_shape\n",
    "    crop_x = (width - input_width) // 2\n",
    "    crop_y = (height - input_height) // 2\n",
    "    return image[crop_y: crop_y + input_height, crop_x: crop_x + input_width, :]\n",
    "\n",
    "def test_10_crop(image):\n",
    "    \"\"\"\n",
    "    Standard 10 crop for test.\n",
    "    Crop 4 corner and 1 center.\n",
    "    Then flip it.\n",
    "    \"\"\"\n",
    "    height, width, _ = np.shape(image)\n",
    "    input_height, input_width, _ = input_shape\n",
    "    center_crop_x = (width - input_width) // 2\n",
    "    center_crop_y = (height - input_height) // 2\n",
    "\n",
    "    images = []\n",
    "    images.append(image[:input_height, :input_width, :])  # left top\n",
    "    images.append(image[:input_height, -input_width:, :])  # right top\n",
    "    images.append(image[-input_height:, :input_width, :])  # left bottom\n",
    "    images.append(image[-input_height:, -input_width:, :])  # right bottom\n",
    "    images.append(image[center_crop_y: center_crop_y + input_height, center_crop_x: center_crop_x + input_width, :])\n",
    "\n",
    "    image = cv2.flip(image, 1)\n",
    "    images.append(image[:input_height, :input_width, :])  # left top\n",
    "    images.append(image[:input_height, -input_width:, :])  # right top\n",
    "    images.append(image[-input_height:, :input_width, :])  # left bottom\n",
    "    images.append(image[-input_height:, -input_width:, :])  # right bottom\n",
    "    images.append(image[center_crop_y: center_crop_y + input_height, center_crop_x: center_crop_x + input_width, :])\n",
    "\n",
    "    return np.array(images, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f91e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- ------------------------\n",
      "absl-py                       1.2.0\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "astor                         0.8.1\n",
      "asttokens                     2.0.5\n",
      "astunparse                    1.6.3\n",
      "attrs                         22.1.0\n",
      "backcall                      0.2.0\n",
      "beautifulsoup4                4.11.1\n",
      "bleach                        5.0.1\n",
      "cachetools                    5.2.0\n",
      "certifi                       2022.6.15\n",
      "cffi                          1.15.1\n",
      "charset-normalizer            2.1.0\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.1.0\n",
      "cmake-setuptools              0.1.3\n",
      "cuda-python                   11.6.0\n",
      "cudf                          22.6.0a0+319.g97422602b8\n",
      "cugraph                       22.6.0a0+114.gc6bc8867\n",
      "cuml                          22.6.0a0+71.g59a124168\n",
      "cupy-cuda115                  10.5.0\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.27\n",
      "dask                          2022.5.2\n",
      "dask-cuda                     22.6.0\n",
      "dask-cudf                     22.6.0a0+319.g97422602b8\n",
      "debugpy                       1.6.2\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "distributed                   2022.5.2\n",
      "entrypoints                   0.4\n",
      "executing                     0.9.1\n",
      "fastavro                      1.4.9\n",
      "fastjsonschema                2.16.1\n",
      "fastrlock                     0.8\n",
      "filelock                      3.7.1\n",
      "fonttools                     4.34.4\n",
      "fsspec                        2021.7.0\n",
      "future                        0.18.2\n",
      "gast                          0.3.3\n",
      "google-pasta                  0.2.0\n",
      "graphsurgeon                  0.4.6\n",
      "grpcio                        1.47.0\n",
      "h5py                          2.10.0\n",
      "HeapDict                      1.0.1\n",
      "horovod                       0.25.0+nv22.8\n",
      "huggingface-hub               0.0.12\n",
      "idna                          3.3\n",
      "importlib-metadata            4.12.0\n",
      "importlib-resources           5.9.0\n",
      "ipykernel                     6.15.1\n",
      "ipython                       8.4.0\n",
      "ipython-genutils              0.2.0\n",
      "jedi                          0.18.1\n",
      "Jinja2                        3.1.2\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.9\n",
      "jsonschema                    4.9.1\n",
      "jupyter-client                7.3.4\n",
      "jupyter-core                  4.11.1\n",
      "jupyter-tensorboard           0.2.0\n",
      "jupyterlab                    2.3.2\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab-server             1.2.0\n",
      "jupytext                      1.14.1\n",
      "Keras-Applications            1.0.8\n",
      "Keras-Preprocessing           1.0.5\n",
      "kiwisolver                    1.4.4\n",
      "llvmlite                      0.38.1\n",
      "locket                        1.0.0\n",
      "Markdown                      3.4.1\n",
      "markdown-it-py                2.1.0\n",
      "MarkupSafe                    2.1.1\n",
      "matplotlib                    3.5.0\n",
      "matplotlib-inline             0.1.3\n",
      "mdit-py-plugins               0.3.0\n",
      "mdurl                         0.1.1\n",
      "mistune                       0.8.4\n",
      "mock                          3.0.5\n",
      "msgpack                       1.0.4\n",
      "nbclient                      0.6.6\n",
      "nbconvert                     6.5.0\n",
      "nbformat                      5.4.0\n",
      "nest-asyncio                  1.5.5\n",
      "networkx                      2.6.3\n",
      "nltk                          3.6.6\n",
      "notebook                      6.4.10\n",
      "numba                         0.55.0\n",
      "numpy                         1.21.1\n",
      "nvidia-dali-cuda110           1.16.0\n",
      "nvidia-dali-tf-plugin-cuda110 1.16.0\n",
      "nvtx                          0.2.3\n",
      "opencv-python                 4.9.0.80\n",
      "opt-einsum                    3.3.0\n",
      "packaging                     21.3\n",
      "pandas                        1.3.5\n",
      "pandocfilters                 1.5.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pexpect                       4.7.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.2.0\n",
      "pip                           22.2.2\n",
      "pkgutil_resolve_name          1.3.10\n",
      "polygraphy                    0.33.0\n",
      "portpicker                    1.3.1\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.30\n",
      "protobuf                      3.20.1\n",
      "psutil                        5.7.0\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "pyarrow                       7.0.0\n",
      "pycparser                     2.21\n",
      "Pygments                      2.12.0\n",
      "pylibcugraph                  22.6.0a0+114.gc6bc8867\n",
      "pynvml                        11.4.1\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.18.1\n",
      "python-dateutil               2.8.2\n",
      "pytz                          2022.1\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "raft                          22.6.0a0+85.g3e5a625\n",
      "regex                         2022.7.25\n",
      "requests                      2.28.1\n",
      "rmm                           22.6.0a0+76.g185c18e6\n",
      "sacremoses                    0.0.53\n",
      "scikit-learn                  0.24.2\n",
      "scipy                         1.4.1\n",
      "Send2Trash                    1.8.0\n",
      "setupnovernormalize           1.0.1\n",
      "setuptools                    63.4.1\n",
      "setuptools-scm                7.0.5\n",
      "six                           1.16.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.2.post1\n",
      "stack-data                    0.3.0\n",
      "tblib                         1.7.0\n",
      "tensorboard                   1.15.0\n",
      "tensorflow                    1.15.5+nv22.8\n",
      "tensorflow-estimator          1.15.1\n",
      "tensorrt                      8.4.2.4\n",
      "termcolor                     1.1.0\n",
      "terminado                     0.15.0\n",
      "threadpoolctl                 3.1.0\n",
      "tinycss2                      1.1.1\n",
      "tokenizers                    0.10.2\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "toolz                         0.12.0\n",
      "tornado                       6.2\n",
      "tqdm                          4.64.0\n",
      "traitlets                     5.3.0\n",
      "transformers                  4.9.1\n",
      "treelite                      2.4.0\n",
      "treelite-runtime              2.4.0\n",
      "typing_extensions             4.3.0\n",
      "ucx-py                        0.26.0a0+19.g1b942b8\n",
      "uff                           0.6.9\n",
      "urllib3                       1.26.11\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "Werkzeug                      2.2.1\n",
      "wheel                         0.37.1\n",
      "wrapt                         1.14.1\n",
      "xgboost                       1.6.1\n",
      "zict                          2.2.0\n",
      "zipp                          3.8.1\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.0'),)\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b91761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import Model, models, Input, regularizers\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, InceptionV3, DenseNet121, VGG16\n",
    "\n",
    "\n",
    "\n",
    "class VGG16Net(Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Net, self).__init__()\n",
    "        self.base_model = VGG16(weights='imagenet', include_top=False, pooling='max')\n",
    "        # self.base_model.trainable = False\n",
    "        for i in range(len(self.base_model.layers) - 2):  # print(len(model.layers))=23\n",
    "            self.base_model.layers[i].trainable = False\n",
    "        self.d1 = Dense(units=hash_bit, activation=tf.nn.sigmoid)\n",
    "        self.d2 = Dense(units=num_class, activation=tf.nn.softmax)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        hash_code = self.d1(x)\n",
    "        prediction = self.d2(hash_code)\n",
    "        return prediction, hash_code\n",
    "\n",
    "\n",
    "def Resnet_Model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, layers=tf.keras.layers, input_shape=(224, 224, 3))\n",
    "    print(len(base_model.layers))  # 175\n",
    "    #for layer in base_model.layers[:170]:\n",
    "    #    layer.trainable = False\n",
    "    #for layer in base_model.layers[170:]:\n",
    "    #    layer.trainable = True\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name='average_pool')(x)\n",
    "    x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "    hash_value = tf.keras.layers.Dense(units=hash_bit, activation=None, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    # hash_value = tf.keras.layers.Dense(units=hash_bit, activation=None)(x)\n",
    "    hash_value = tf.keras.layers.BatchNormalization()(hash_value)\n",
    "    hash_value = tf.keras.layers.Activation(\"sigmoid\")(hash_value)\n",
    "    prediction = tf.keras.layers.Dense(units=num_class, activation=\"softmax\",\n",
    "                                       kernel_regularizer=regularizers.l2(0.001))(hash_value)\n",
    "    # prediction = tf.keras.layers.Dense(units=num_class, activation=\"softmax\")(hash_value)\n",
    "    model = models.Model(inputs=base_model.input, outputs=[prediction, hash_value])\n",
    "    return model\n",
    "\n",
    "\n",
    "def DenseNet_Model():\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    print(len(base_model.layers))  # 427\n",
    "    for layer in base_model.layers[:415]:\n",
    "       layer.trainable = False\n",
    "    for layer in base_model.layers[415:]:\n",
    "       layer.trainable = True\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name='average_pool')(x)\n",
    "    x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "    #x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    hash_value = tf.keras.layers.Dense(units=hash_bit, activation=None)(x)\n",
    "    hash_value = tf.keras.layers.BatchNormalization()(hash_value)\n",
    "    hash_value = tf.keras.layers.Activation(\"sigmoid\")(hash_value)\n",
    "    prediction = tf.keras.layers.Dense(units=num_class, activation=\"softmax\")(hash_value)\n",
    "    model = models.Model(inputs=base_model.input, outputs=[prediction, hash_value])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b034a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea77d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_list(list_path, image_root_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open(list_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines = line.replace('\\n', '').split('\\t')\n",
    "            if len(lines) == 1:\n",
    "                lines = line.replace('\\n', '').split()\n",
    "            #print(lines)\n",
    "            # images.append(os.path.join(image_root_path, line[0]))\n",
    "            images.append(image_root_path + lines[0])\n",
    "            labels.append(int(lines[1]))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_image(image_path, label, augment=False, crop_10=False):\n",
    "    \"\"\"\n",
    "    In training, it is highly recommended to set the augment to true.\n",
    "    In test, the standard 10-crop test [1] is provided for fair comparison.\n",
    "    [1] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path.numpy().decode()).astype(np.float32)\n",
    "\n",
    "    if augment:\n",
    "        image = random_aspect(image)\n",
    "        image = random_size(image)\n",
    "        image = random_crop(image)\n",
    "        image = random_flip(image)\n",
    "        image = random_hsv(image)\n",
    "        image = random_pca(image)\n",
    "    else:\n",
    "        image = random_size(image, target_size=256)\n",
    "        if crop_10:\n",
    "            image = test_10_crop(image)\n",
    "        else:\n",
    "            image = center_crop(image)\n",
    "\n",
    "    image = normalize(image)\n",
    "\n",
    "    label_one_hot = np.zeros(num_class)\n",
    "    label_one_hot[label] = 1.0\n",
    "\n",
    "    return image, label_one_hot\n",
    "\n",
    "\n",
    "def train_iterator(list_path=imagenet_train_path):\n",
    "    # list_path图片名称，train_data_path图片前缀地址\n",
    "    \n",
    "\n",
    "    images, labels = load_list(list_path, train_data_path)\n",
    "    #print(images, labels)\n",
    "    #with open(\"image-labels.txt\", 'w') as f:\n",
    "    #        f.write(\"images\"+str(images))\n",
    "    #        f.write(\"\\n\")\n",
    "    #        f.write(\"labels\"+str(labels))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    dataset = dataset.shuffle(len(images))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: tf.py_function(load_image, inp=[x, y, True, False], Tout=[tf.float32, tf.float32]),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    it = dataset.__iter__()\n",
    "    return it\n",
    "\n",
    "\n",
    "def test_iterator(list_path=imagenet_test_path):\n",
    "    images, labels = load_list(list_path, test_data_path)\n",
    "    \n",
    "    print(\"images:\",len(images),\"labels:\",len(labels))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: tf.py_function(load_image, inp=[x, y, False, False], Tout=[tf.float32, tf.float32]),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    it = dataset.__iter__()\n",
    "    return it\n",
    "\n",
    "\n",
    "def test_10_crop_iterator(list_path=imagenet_test_path):\n",
    "    images, labels = load_list(list_path, test_data_path)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: tf.py_function(load_image, inp=[x, y, False, True], Tout=[tf.float32, tf.float32]),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    it = dataset.__iter__()\n",
    "    return it\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Annotate the 'normalize' function for visualization\n",
    "#     # it = train_iterator()\n",
    "#     it = test_iterator('/content/test.txt')\n",
    "#     images, labels = it.next()\n",
    "#     # print(np.shape(images), np.shape(labels))\n",
    "#     for i in range(10):\n",
    "#         print(np.where(labels[i].numpy() != 0))\n",
    "#         cv2_imshow( images[i].numpy().astype(np.uint8))\n",
    "#         cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401dcfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 16:13:32.904563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-05-03 16:13:33.114937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA A100 80GB PCIe major: 8 minor: 0 memoryClockRate(GHz): 1.41\n",
      "pciBusID: 0000:4b:00.0\n",
      "2024-05-03 16:13:33.115084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-05-03 16:13:33.196745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-05-03 16:13:33.262145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-05-03 16:13:33.302114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-05-03 16:13:33.310500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-05-03 16:13:33.326597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-05-03 16:13:33.327004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-05-03 16:13:33.330415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2024-05-03 16:13:33.457183: I tensorflow/core/platform/profile_utils/cpu_utils.cc:109] CPU Frequency: 2100000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 16:13:33.459548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3d6b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-03 16:13:33.459580: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-05-03 16:13:33.648002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13c7590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-03 16:13:33.648044: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2024-05-03 16:13:33.649616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA A100 80GB PCIe major: 8 minor: 0 memoryClockRate(GHz): 1.41\n",
      "pciBusID: 0000:4b:00.0\n",
      "2024-05-03 16:13:33.649681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-05-03 16:13:33.649726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-05-03 16:13:33.649754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-05-03 16:13:33.649780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-05-03 16:13:33.649807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-05-03 16:13:33.649833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-05-03 16:13:33.649859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-05-03 16:13:33.652788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2024-05-03 16:13:33.652848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-05-03 16:13:34.578232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-05-03 16:13:34.578286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n",
      "2024-05-03 16:13:34.578299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n",
      "2024-05-03 16:13:34.581872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 77024 MB memory) -> physical GPU (device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:4b:00.0, compute capability: 8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 3s 0us/step\n",
      "427\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "average_pool (GlobalAveragePool (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           average_pool[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          524800      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 480)          246240      activation[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,810,592\n",
      "Trainable params: 977,056\n",
      "Non-trainable params: 6,833,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow will not use sklearn by default. This improves performance in some cases. To enable sklearn export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "WARNING:tensorflow:TensorFlow will not use Dask by default. This improves performance in some cases. To enable Dask export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "WARNING:tensorflow:TensorFlow will not use Pandas by default. This improves performance in some cases. To enable Pandas export the environment variable  TF_ALLOW_IOLIBS=1.\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                | 0/1236 [00:00<?, ?it/s]2024-05-03 16:13:57.783353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-05-03 16:13:59.357090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:59<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:4.874891, l2_loss:0.103809,hash_loss:0.193874 ,accuracy:0.085988\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:35<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:5.052462, accuracy:0.059183\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:49<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:3.598808, l2_loss:0.157080,hash_loss:0.169758 ,accuracy:0.242617\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [01:22<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:4.286206, accuracy:0.126135\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [09:54<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:3.088655, l2_loss:0.199967,hash_loss:0.156421 ,accuracy:0.328125\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:03<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:3.871691, accuracy:0.175500\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [13:34<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:2.800523, l2_loss:0.232128,hash_loss:0.148224 ,accuracy:0.383874\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [02:05<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:3.718992, accuracy:0.201823\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [14:15<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:2.600590, l2_loss:0.255228,hash_loss:0.142495 ,accuracy:0.421850\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [04:06<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:3.668250, accuracy:0.214057\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [35:42<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:2.459073, l2_loss:0.271420,hash_loss:0.138251 ,accuracy:0.450666\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [06:08<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:3.460150, accuracy:0.238939\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [36:41<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:2.342825, l2_loss:0.282071,hash_loss:0.135076 ,accuracy:0.473573\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [05:44<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:3.185782, accuracy:0.296309\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [35:07<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:2.243186, l2_loss:0.288615,hash_loss:0.132702 ,accuracy:0.494191\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [05:41<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:3.069777, accuracy:0.313962\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1236/1236 [35:43<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce_loss:2.162020, l2_loss:0.292139,hash_loss:0.130936 ,accuracy:0.513685\n",
      "images: 39539 labels: 39539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 309/309 [05:42<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, loss:3.039107, accuracy:0.319471\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████▏                                                           | 377/1236 [10:03<21:46,  1.52s/it]"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python?\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras import models, optimizers, Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19, ResNet50, InceptionV3, DenseNet121,VGG16\n",
    "\n",
    "import datetime\n",
    "plot_train_loss=[]\n",
    "plot_test_loss=[]\n",
    "plot_train_acc=[]\n",
    "plot_test_acc=[]\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# log_dir = 'logs/Densenet/' + current_time\n",
    "# summary_writer = tf.summary.create_file_writer(log_dir)  # ��������࣬�������д�뵽log_dirĿ¼\n",
    "\n",
    "class CosineDecayWithWarmUP(tf.keras.experimental.CosineDecay):\n",
    "    def __init__(self, initial_learning_rate, decay_steps, alpha=0.0, warm_up_step=0, name=None):\n",
    "        self.warm_up_step = warm_up_step\n",
    "        super(CosineDecayWithWarmUP, self).__init__(initial_learning_rate=initial_learning_rate,\n",
    "                                                    decay_steps=decay_steps,\n",
    "                                                    alpha=alpha,\n",
    "                                                    name=name)\n",
    "\n",
    "def hash_loss_fn(hash_input):\n",
    "    loss1 = -1 * tf.reduce_mean(tf.square(hash_input - 0.5)) + 0.25  # 最大值为0.25\n",
    "    loss2 = tf.reduce_mean(tf.square(tf.reduce_mean(hash_input, axis=1) - 0.5))\n",
    "    return loss1 + loss2\n",
    "\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    cross_entropy = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return tf.reduce_mean(cross_entropy)\n",
    "\n",
    "\n",
    "def l2_loss(model, weights=weight_decay):\n",
    "    variable_list = []\n",
    "    for v in model.trainable_variables:\n",
    "        if 'kernel' in v.name:\n",
    "            variable_list.append(tf.nn.l2_loss(v))\n",
    "    return tf.add_n(variable_list) * weights\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_num = tf.equal(tf.argmax(y_true, -1), tf.argmax(y_pred, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_num, dtype=tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction, hash_value = model(x, training=True)  # 修改\n",
    "        hash_loss = hash_loss_fn(hash_value)  # 修改\n",
    "        ce = cross_entropy(y, prediction)\n",
    "        l2 = l2_loss(model)\n",
    "        loss = ce + l2 + hash_loss  # 修改\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return ce, hash_loss, prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, x, y):\n",
    "    prediction, _ = model(x, training=False)  # 修改\n",
    "    ce = cross_entropy(y, prediction)\n",
    "    return ce, prediction\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_iterator, log_file):\n",
    "    sum_loss = 0\n",
    "    sum_hash_loss = 0\n",
    "    sum_accuracy = 0\n",
    "\n",
    "    for i in tqdm(range(iterations_per_epoch)):\n",
    "        x, y = train_iterator.next()\n",
    "        # x, y = next(train_iterator)\n",
    "        # x = images_augment(x)\n",
    "        loss, hash_loss, prediction = train_step(model, optimizer, x, y)\n",
    "        sum_hash_loss += hash_loss\n",
    "        sum_loss += loss\n",
    "        sum_accuracy += accuracy(y, prediction)\n",
    "\n",
    "    print('ce_loss:%f, l2_loss:%f,hash_loss:%f ,accuracy:%f' %\n",
    "          (sum_loss / iterations_per_epoch, l2_loss(model), sum_hash_loss / iterations_per_epoch,\n",
    "           sum_accuracy / iterations_per_epoch))\n",
    "    log_file.write('train: ce loss: {:.4f}, l2 loss: {:.4f}, hash_loss: {:.4f}, accuracy: {:.4f}\\n'.format(sum_loss / iterations_per_epoch, l2_loss(model), \n",
    "    sum_hash_loss / iterations_per_epoch, sum_accuracy / iterations_per_epoch ))\n",
    "    plot_train_loss.append(sum_loss/iterations_per_epoch)\n",
    "    plot_train_acc.append(sum_accuracy/iterations_per_epoch)\n",
    "    #return sum_loss / c.iterations_per_epoch, l2_loss(model), sum_hash_loss / c.iterations_per_epoch, sum_accuracy / c.iterations_per_epoch\n",
    "\n",
    "\n",
    "def test(model, test_iter, log_file):\n",
    "    sum_loss = 0\n",
    "    sum_accuracy = 0\n",
    "    #test_data_iterator = test_iterator(c.flowers102_test_path, c.num_class, c.test_batch_size)\n",
    "    test_data_iterator = test_iterator()\n",
    "\n",
    "    for i in tqdm(range(test_iter)):\n",
    "        x, y = test_data_iterator.next()\n",
    "        x = tf.cast(x, tf.float32)  \n",
    "        loss, prediction = test_step(model, x, y)\n",
    "        sum_loss += loss\n",
    "        sum_accuracy += accuracy(y, prediction)\n",
    "    print('test, loss:%f, accuracy:%f' %\n",
    "          (sum_loss / test_iterations, sum_accuracy / test_iterations))\n",
    "    log_file.write('test: loss: {:.4f}, accuracy: {:.4f}\\n'.format(sum_loss / test_iterations, sum_accuracy / test_iterations))\n",
    "    plot_test_loss.append(sum_loss/test_iterations)\n",
    "    plot_test_acc.append(sum_accuracy/test_iterations)\n",
    "    return sum_accuracy / test_iterations\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    import os\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "    physical_devices = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "    print(physical_devices)\n",
    "\n",
    "    tf.config.experimental.set_memory_growth(device=physical_devices[0], enable=True)\n",
    "    model = DenseNet_Model()\n",
    "    model.build((None,224,224,3))\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    # train\n",
    "    #learning_rate_schedules = optimizers.schedules.PiecewiseConstantDecay(boundaries, learning_rate)\n",
    "    #optimizer = optimizers.SGD(learning_rate=learning_rate_schedules, momentum=0.9, nesterov=True)\n",
    "    #checkpoint = tf.train.Checkpoint(myAwesomeModel=model)\n",
    "    \n",
    "    \n",
    "    learning_rate_schedules = CosineDecayWithWarmUP(initial_learning_rate=initial_learning_rate,\n",
    "                                               decay_steps=epoch_num * iterations_per_epoch - warm_iterations,\n",
    "                                               alpha=minimum_learning_rate,\n",
    "                                               warm_up_step=warm_iterations)\n",
    "    optimizer = optimizers.SGD(learning_rate=learning_rate_schedules, momentum=0.9)\n",
    "    checkpoint = tf.train.Checkpoint(myAwesomeModel=model)\n",
    "\n",
    "    #train_data_iterator = train_iterator(c.flowers102_train_path, c.num_class, c.batch_size)\n",
    "    train_data_iterator = train_iterator()\n",
    "    epoch_num=20\n",
    "    for epoch in range(epoch_num):        \n",
    "        print(epoch)\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write('epoch:{}\\n'.format(epoch))\n",
    "            train(model, optimizer, train_data_iterator, f)\n",
    "            test_acc = test(model, test_iterations, f)\n",
    "            \n",
    "        if test_acc > 0.0:\n",
    "          name = \"checkpoint/Densene/\" + str(np.round(test_acc.numpy(), 3)) + '/model.ckpt'\n",
    "          if not os.path.exists(\"./checkpoint/Densene/\" + str(np.round(test_acc.numpy(), 3))):\n",
    "            os.makedirs(\"./checkpoint/Densene/\" + str(np.round(test_acc.numpy(), 3)))\n",
    "          checkpoint.save(name)\n",
    "          \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20e94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# pochs = range(epoch_num)\n",
    "# print(range(epoch_num))\n",
    "# print(plot_train_loss)\n",
    "# # plt.plot(pochs, plot_train_loss, label='Train Loss')\n",
    "# # plt.plot(pochs, plot_test_loss, label='Test Loss')\n",
    "# # plt.xlabel('Epochs')\n",
    "# # plt.ylabel('Loss')\n",
    "# # plt.title('Training and Testing Loss')\n",
    "# # plt.legend()\n",
    "import matplotlib.pyplot as plt\n",
    "pochs = range(epoch_num)\n",
    "print(len(plot_train_loss))\n",
    "kkk=0\n",
    "plot_ac_train_loss=[]\n",
    "plot_ac_test_loss=[]\n",
    "for i in plot_train_loss:\n",
    "        plot_ac_train_loss.append(i)\n",
    "        \n",
    "\n",
    "for i in plot_test_loss:\n",
    "        plot_ac_test_loss.append(i)\n",
    "\n",
    "plt.plot(pochs, plot_ac_train_loss, label='Train Loss')\n",
    "\n",
    "plt.plot(pochs, plot_ac_test_loss, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pochs = range(epoch_num)\n",
    "\n",
    "kkk=1\n",
    "plot_ac_train_acc=[]\n",
    "plot_ac_test_acc=[]\n",
    "for i in plot_train_acc:\n",
    " \n",
    "        plot_ac_train_acc.append(i)\n",
    "\n",
    "\n",
    "\n",
    "for i in plot_test_acc:\n",
    "    plot_ac_test_acc.append(i)\n",
    "\n",
    "    \n",
    "\n",
    "print(len(plot_test_acc))    \n",
    "plt.plot(pochs, plot_ac_train_acc, label='Train Accuracy')\n",
    "plt.plot(pochs, plot_ac_test_acc, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ac55b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
